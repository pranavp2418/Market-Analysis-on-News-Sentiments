{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c6c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "import bt\n",
    "class SelectWhere(bt.Algo):\n",
    "\n",
    "    \"\"\"\n",
    "    Selects securities where the value is True on the current date (target.now).\n",
    "    Args:\n",
    "        * signal: DataFrame containing the signal (boolean DataFrame)\n",
    "    \"\"\"\n",
    "    def __init__(self, signal):\n",
    "        self.signal = signal\n",
    "    # - - - - - - - - - -\n",
    "    def __call__(self, target):\n",
    "        # get signal on target.now\n",
    "        if target.now in self.signal.index: \n",
    "            sig = self.signal.loc[target.now]\n",
    "\n",
    "            # get indices where true as list\n",
    "            selected = list(sig.index[sig])\n",
    "\n",
    "            # save in temp - this will be used by the weighing algo\n",
    "            target.temp['selected'] = selected  \n",
    "\n",
    "        # return True because we want to keep on moving down the stack\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce3361-005e-4c5c-8c3d-25075a046293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ticker/it_tickers.csv')\n",
    "tickers= np.array(df['Symbol'])\n",
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46378cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trend_strategy = {}\n",
    "trend_strategy = {}\n",
    "ticker_strategies={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f61985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_return(df):\n",
    "    df['positive_return_dummy'] = (df[f'Daily Return(%)_{ticker}'] > 0).astype(int)\n",
    "\n",
    "def calculate_best_ema_ratio(df, ticker):\n",
    "    ema_ratios = {}\n",
    "    '''\n",
    "    ema_ratios['EMA5/10'] = (df[f'EMA5_{ticker}'] / df[f'EMA10_{ticker}']).mean() / (df[f'EMA5_{ticker}'] / df[f'EMA10_{ticker}']).std()\n",
    "    ema_ratios['EMA10/30'] = (df[f'EMA10_{ticker}'] / df[f'EMA30_{ticker}']).mean() / (df[f'EMA10_{ticker}'] / df[f'EMA30_{ticker}']).std()\n",
    "    ema_ratios['EMA30/60'] = (df[f'EMA30_{ticker}'] / df[f'EMA60_{ticker}']).mean() / (df[f'EMA30_{ticker}'] / df[f'EMA60_{ticker}']).std()\n",
    "    ema_ratios['EMA30/100'] = (df[f'EMA30_{ticker}'] / df[f'EMA100_{ticker}']).mean() / (df[f'EMA30_{ticker}'] / df[f'EMA100_{ticker}']).std()\n",
    "    '''\n",
    "    df['EMA5/10'] = df[f'EMA5_{ticker}'] / df[f'EMA10_{ticker}']\n",
    "    df['EMA10/30'] = df[f'EMA10_{ticker}'] / df[f'EMA30_{ticker}']\n",
    "    df['EMA30/60'] = df[f'EMA30_{ticker}'] / df[f'EMA60_{ticker}']\n",
    "    df['EMA30/100'] = df[f'EMA30_{ticker}'] / df[f'EMA100_{ticker}']\n",
    "    \n",
    "    #df['SMA5/10'] = np.where()\n",
    "    df['forward_return'] = df[f'Daily_Return_{ticker}']\n",
    "    df['R_EMA5/10'] = (df['EMA5/10']>1).astype(int)*2-1\n",
    "    df['R_EMA10/30'] = (df['EMA10/30']>1).astype(int)*2-1\n",
    "    df['R_EMA30/60'] = (df['EMA30/60']>1).astype(int)*2-1\n",
    "    df['R_EMA30/100'] = (df['EMA30/100']>1).astype(int)*2-1\n",
    "    ema_ratios['EMA5/10'] = (df['R_EMA5/10'].shift(1)*df['forward_return']).mean() /(df['R_EMA5/10'].shift(1)*df['forward_return']).std()*math.sqrt(260)\n",
    "    ema_ratios['EMA10/30'] = (df['R_EMA10/30'].shift(1)*df['forward_return']).mean() /(df['R_EMA10/30'].shift(1)*df['forward_return']).std()*math.sqrt(260)\n",
    "    ema_ratios['EMA30/60'] = (df['R_EMA30/60'].shift(1)*df['forward_return']).mean() /(df['R_EMA30/60'].shift(1)*df['forward_return']).std()*math.sqrt(260)\n",
    "    ema_ratios['EMA30/100'] = (df['R_EMA30/100'].shift(1)*df['forward_return']).mean() /(df['R_EMA30/100'].shift(1)*df['forward_return']).std()*math.sqrt(260)\n",
    "\n",
    "    \n",
    "    print(ticker)\n",
    "    print(type(ticker))\n",
    "    best_ratio = max(ema_ratios, key=ema_ratios.get)\n",
    "    print(ema_ratios[best_ratio])\n",
    "    best_trend_strategy[ticker].add((best_ratio, ema_ratios[best_ratio]))\n",
    "    return best_ratio\n",
    "\n",
    "def calculate_ema_ratio(df, ticker,selected_ratio):\n",
    "    print(selected_ratio)\n",
    "    if selected_ratio == 'EMA5/10':\n",
    "        df['ema_ratio'] = df[f'EMA5_{ticker}'] / df[f'EMA10_{ticker}']\n",
    "    elif selected_ratio == 'EMA10/30':\n",
    "        df['ema_ratio'] = df[f'EMA10_{ticker}'] / df[f'EMA30_{ticker}']\n",
    "    elif selected_ratio == 'EMA30/60':\n",
    "        df['ema_ratio'] = df[f'EMA30_{ticker}'] / df[f'EMA60_{ticker}']\n",
    "    elif selected_ratio == 'EMA30/100':\n",
    "        df['ema_ratio'] = df[f'EMA30_{ticker}'] / df[f'EMA100_{ticker}']\n",
    "    else:\n",
    "        raise ValueError(\"Invalid ratio selected.\")\n",
    "    df['R_ema_ratio'] = (df['ema_ratio']>1).astype(int)*2-1\n",
    "    df['ret_ema_ratio'] = df['R_ema_ratio'].shift(1)*df[f'Daily_Return_{ticker}']\n",
    "    \n",
    "def calculate_best_sma_ratio(df, ticker):\n",
    "    sma_ratios = {}\n",
    "    #sma_ratios['SMA5/10'] = (df[f'SMA5_{ticker}'] / df[f'SMA10_{ticker}']).mean() / (df[f'SMA5_{ticker}'] / df[f'SMA10_{ticker}']).std()\n",
    "    df['SMA5/10'] = df[f'SMA5_{ticker}'] / df[f'SMA10_{ticker}']\n",
    "    df['SMA10/30'] = df[f'SMA10_{ticker}'] / df[f'SMA30_{ticker}']\n",
    "    df['SMA30/60'] = df[f'SMA30_{ticker}'] / df[f'SMA60_{ticker}']\n",
    "    df['SMA30/100'] = df[f'SMA30_{ticker}'] / df[f'SMA100_{ticker}']\n",
    "    \n",
    "    #df['SMA5/10'] = np.where()\n",
    "    df['forward_return'] = df[f'Daily_Return_{ticker}']\n",
    "    df['R_SMA5/10'] = (df['SMA5/10']>1).astype(int)*2-1\n",
    "    df['R_SMA10/30'] = (df['SMA10/30']>1).astype(int)*2-1\n",
    "    df['R_SMA30/60'] = (df['SMA30/60']>1).astype(int)*2-1\n",
    "    df['R_SMA30/100'] = (df['SMA30/100']>1).astype(int)*2-1\n",
    "    sma_ratios['SMA5/10'] = (df['R_SMA5/10'].shift(1)*df['forward_return']).mean() /(df['R_SMA5/10'].shift(1)*df['forward_return']).std()*math.sqrt(260)\n",
    "    sma_ratios['SMA10/30'] = (df['R_SMA10/30'].shift(1)*df['forward_return']).mean() /(df['R_SMA10/30'].shift(1)*df['forward_return']).std()*math.sqrt(260)\n",
    "    sma_ratios['SMA30/60'] = (df['R_SMA30/60'].shift(1)*df['forward_return']).mean() /(df['R_SMA30/60'].shift(1)*df['forward_return']).std()*math.sqrt(260)\n",
    "    sma_ratios['SMA30/100'] = (df['R_SMA30/100'].shift(1)*df['forward_return']).mean() /(df['R_SMA30/100'].shift(1)*df['forward_return']).std()*math.sqrt(260)\n",
    "\n",
    "    #sma_ratios['SMA30/100'] = (df[f'SMA30_{ticker}'] / df[f'SMA100_{ticker}']).mean() / (df[f'SMA30_{ticker}'] / df[f'SMA100_{ticker}']).std()\n",
    "    #print(ticker)\n",
    "    #print(type(ticker))\n",
    "    \n",
    "    best_ratio = max(sma_ratios, key=sma_ratios.get)\n",
    "    print(sma_ratios[best_ratio])\n",
    "    df['RetMACD'] = df[f'RetMACD_{ticker}'].shift(1)\n",
    "    best_trend_strategy[ticker]= set()\n",
    "    best_trend_strategy[ticker].add((best_ratio, sma_ratios[best_ratio]))\n",
    "    best_trend_strategy[ticker].add(('RetMACD',df['RetMACD'].mean()/df['RetMACD'].std()*math.sqrt(260)))\n",
    "    return best_ratio\n",
    "\n",
    "def calculate_sma_ratio(df, ticker,selected_ratio):\n",
    "    print(selected_ratio)\n",
    "    if selected_ratio == 'SMA5/10':\n",
    "        df['sma_ratio'] =  df[f'SMA5_{ticker}'] / df[f'SMA10_{ticker}']\n",
    "        \n",
    "    elif selected_ratio == 'SMA10/30':\n",
    "        df['sma_ratio'] =  df[f'SMA10_{ticker}'] / df[f'SMA30_{ticker}']\n",
    "        \n",
    "    elif selected_ratio == 'SMA30/60':\n",
    "        df['sma_ratio'] =  df[f'SMA30_{ticker}'] / df[f'SMA60_{ticker}']\n",
    "\n",
    "    elif selected_ratio == 'SMA30/100':\n",
    "        df['sma_ratio'] =  df[f'SMA30_{ticker}'] / df[f'SMA100_{ticker}']  \n",
    "    else:\n",
    "        raise ValueError(\"Invalid ratio selected.\")\n",
    "    df['RetMACD'] = df[f'RetMACD_{ticker}'].shift(1)\n",
    "    df['R_sma_ratio'] = (df['sma_ratio']>1).astype(int)*2-1\n",
    "    df['ret_sma_ratio'] = df['R_sma_ratio'].shift(1)*df[f'Daily_Return_{ticker}']\n",
    "def calculate_best_volatility_ratio(df, ticker):\n",
    "    vol_ratios = {}\n",
    "    '''\n",
    "    vol_ratios['Volatility5/10'] = (df[f'Vol5_{ticker}'] / df[f'Vol10_{ticker}']).mean()/(df[f'Vol5_{ticker}'] / df[f'Vol10_{ticker}']).std()\n",
    "    vol_ratios['Volatility10/20'] = (df[f'Vol10_{ticker}'] / df[f'Vol20_{ticker}']).mean()/(df[f'Vol10_{ticker}'] / df[f'Vol20_{ticker}']).std()\n",
    "    vol_ratios['Volatility20/60'] = (df[f'Vol20_{ticker}'] / df[f'Vol60_{ticker}']).mean()/(df[f'Vol20_{ticker}'] / df[f'Vol60_{ticker}']).std()\n",
    "    '''\n",
    "    df['Vol5/10'] = df[f'Vol5_{ticker}'] / df[f'Vol10_{ticker}']\n",
    "    df['Vol10/20'] = df[f'Vol10_{ticker}'] / df[f'Vol20_{ticker}']\n",
    "    df['Vol20/60'] = df[f'Vol20_{ticker}'] / df[f'Vol60_{ticker}']\n",
    "    #df['SMA30/100'] = df[f'SMA30_{ticker}'] / df[f'SMA100_{ticker}']\n",
    "    \n",
    "    #df['SMA5/10'] = np.where()\n",
    "    df['forward_return'] = df[f'Daily_Return_{ticker}']\n",
    "    df['R_Vol5/10'] = (df['Vol5/10']>1).astype(int)*2-1\n",
    "    df['R_Vol10/20'] = (df['Vol10/20']>1).astype(int)*2-1\n",
    "    df['R_Vol20/60'] = (df['Vol20/60']>1).astype(int)*2-1\n",
    "    #df['R_SMA30/100'] = (df['SMA30/100']>1).astype(int)*2-1\n",
    "    vol_ratios['Vol5/10'] = (df['R_Vol5/10'].shift(1)*df['forward_return']).mean() /(df['R_Vol5/10'].shift(1)*df['forward_return']).std()*math.sqrt(260)\n",
    "    vol_ratios['Vol10/20'] = (df['R_Vol10/20'].shift(1)*df['forward_return']).mean() /(df['R_Vol10/20'].shift(1)*df['forward_return']).std()*math.sqrt(260)\n",
    "    vol_ratios['Vol20/60'] = (df['R_Vol20/60'].shift(1)*df['forward_return']).mean() /(df['R_Vol20/60'].shift(1)*df['forward_return']).std()*math.sqrt(260)\n",
    "    #sma_ratios['SMA30/100'] = (df['R_SMA30/100'].shift(1)*df['forward_return']).mean() /(df['R_SMA30/100'].shift(1)*df['forward_return']).std()*math.sqrt(260)\n",
    "\n",
    "    best_ratio = max(vol_ratios, key=vol_ratios.get)\n",
    "    best_trend_strategy[ticker].add((best_ratio, vol_ratios[best_ratio]))\n",
    "    return best_ratio\n",
    "def calculate_volitility_ratio(df,ticker, selected_ratio):\n",
    "    print(selected_ratio)\n",
    "    if selected_ratio == 'Vol5/10':\n",
    "        df['volatility_ratio'] = df[f'Vol5_{ticker}'] / df[f'Vol10_{ticker}']\n",
    "    elif selected_ratio == 'Vol10/20':\n",
    "        df['volatility_ratio'] = df[f'Vol10_{ticker}'] / df[f'Vol20_{ticker}']\n",
    "    elif selected_ratio == 'Vol20/60':\n",
    "        df['volatility_ratio'] = df[f'Vol20_{ticker}'] / df[f'Vol60_{ticker}']\n",
    "    else:\n",
    "        raise ValueError(\"Invalid ratio selected.\")\n",
    "    df['R_vol_ratio'] = (df['volatility_ratio']>1).astype(int)*2-1\n",
    "    df['ret_vol_ratio'] = df['R_vol_ratio'].shift(1)*df[f'Daily_Return_{ticker}']\n",
    "def calculate_sharpe_ratio(df,signals_df, signal, ticker):\n",
    "    column_name = f'Daily_Return_{ticker}_L01d'\n",
    "    df[f'ret_{signal}'] = signals_df[f'signal_{signal}'].shift(1) * df[column_name]\n",
    "    df[F'{signal}'] = signals_df[f'signal_{signal}']\n",
    "    daily_return = df[f'ret_{signal}'].dropna()\n",
    "    sharpe_ratio = (daily_return.mean() / daily_return.std()) * math.sqrt(260)  # Assuming 252 trading days in a year\n",
    "    \n",
    "    return sharpe_ratio\n",
    "\n",
    "def calculate_best_strategy(test_df, signals, ticker):\n",
    "    sharpe_ratios = {}\n",
    "    \n",
    "    for signal in signals:\n",
    "        sharpe_ratio = calculate_sharpe_ratio(test_df, signals_df,signal, ticker)\n",
    "        sharpe_ratios[signal] = sharpe_ratio\n",
    "    \n",
    "    best_strategy = max(sharpe_ratios, key=sharpe_ratios.get)\n",
    "    \n",
    "    return best_strategy, sharpe_ratios\n",
    "\n",
    "def merge_data(df, ticker, new_csv, date_column):\n",
    "    \n",
    "    df2 = pd.read_csv(new_csv)\n",
    "    \n",
    "    # Rename and convert date column to datetime\n",
    "    df2 = df2.rename(columns={'time': date_column})\n",
    "    df2[date_column] = pd.to_datetime(df2[date_column])\n",
    "    \n",
    "    # Merge sentiment data with existing DataFrame\n",
    "    merged_df = df.merge(df2, how='outer', on=date_column)\n",
    "    \n",
    "    # Drop rows with NaN values in the 'Open_{ticker}' column\n",
    "    merged_df = merged_df.dropna(subset=[f'Open_{ticker}'])\n",
    "    \n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d57a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "avoid_tickers=['ANET','CDW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5831d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in tickers:\n",
    "    file_path = f'ticker/data/{ticker}.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    sheet_name = ticker\n",
    "    if ticker in avoid_tickers:\n",
    "        continue\n",
    "    date_column = f'Date_{sheet_name}'\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "\n",
    "    df.drop(columns=[f'Hit?_{sheet_name}', f'Hit?_{sheet_name}',f'Hit?_{sheet_name}', f'HitAt_2.2_{sheet_name}',\n",
    "                    f'HitAt_2.0_{sheet_name}',f'HitAt_1.8_{sheet_name}',f'ExitPr_2.2_{sheet_name}',\n",
    "                    f'ExitPr_2.0_{sheet_name}',f'ExitPr_1.8_{sheet_name}', f'ret_2.2_{sheet_name}',\n",
    "                    f'Ret2.0_{sheet_name}', f'Ret_1.8_{sheet_name}'], inplace=True)\n",
    "    df.drop(columns=[f'Hit?_{sheet_name}.1'], inplace=True)\n",
    "    df.drop(columns = [f'Hit?_{sheet_name}.2'], inplace=True)\n",
    "\n",
    "    #print(df)\n",
    "    #output_path =f'ticker/{sheet_name}.csv'\n",
    "    #df.to_csv(output_path,index=False)\n",
    "    target_variable = 'positive_return_dummy'\n",
    "    positive_return(df)\n",
    "    df = df.rename(columns = {f'Daily Return(%)_{ticker}':f'Daily_Return_{ticker}'})\n",
    "\n",
    "    start_date = '2018-01-01'\n",
    "    end_date = '2022-12-31'\n",
    "    train_df = train_df = df[(df[date_column] >= start_date) & (df[date_column] <= end_date)]\n",
    "    train_df['positive_return_dummy'] = train_df['positive_return_dummy'].shift(-1)\n",
    "\n",
    "    start_date_test = '2023-01-01'\n",
    "    end_date_test = '2023-12-31'\n",
    "    start_date_out_of_sample = '2024-01-01'\n",
    "\n",
    "    test_df = df[(df[date_column] >= start_date_test) & (df[date_column] <= end_date_test)]\n",
    "    test_df['positive_return_dummy'] = test_df['positive_return_dummy'].shift(-1)\n",
    "    test_df.dropna()\n",
    "    print(len(test_df))\n",
    "\n",
    "    out_of_sample_df = df[df[date_column] >= start_date_out_of_sample]\n",
    "    out_of_sample_df['positive_return_dummy'] = out_of_sample_df['positive_return_dummy'].shift(-1)\n",
    "    out_of_sample_df.dropna()\n",
    "    print(len(out_of_sample_df))\n",
    "\n",
    "    calculate_sma_ratio(train_df,ticker, calculate_best_sma_ratio(train_df,ticker))\n",
    "    calculate_sma_ratio(test_df, ticker,calculate_best_sma_ratio(train_df,ticker))\n",
    "    calculate_sma_ratio(out_of_sample_df,ticker, calculate_best_sma_ratio(train_df,ticker))\n",
    "\n",
    "    calculate_ema_ratio(train_df,ticker, calculate_best_ema_ratio(train_df,ticker))\n",
    "    calculate_ema_ratio(test_df,ticker, calculate_best_ema_ratio(train_df,ticker))\n",
    "    calculate_ema_ratio(out_of_sample_df,ticker, calculate_best_ema_ratio(train_df,ticker))\n",
    "\n",
    "    calculate_volitility_ratio(train_df,ticker,calculate_best_volatility_ratio(train_df,ticker))\n",
    "    calculate_volitility_ratio(test_df,ticker,calculate_best_volatility_ratio(train_df,ticker))\n",
    "    calculate_volitility_ratio(out_of_sample_df,ticker,calculate_best_volatility_ratio(train_df,ticker))\n",
    "    print(test_df)\n",
    "\n",
    "\n",
    "    train_df[f'Date_{ticker}'] = pd.to_datetime(train_df[f'Date_{ticker}'])\n",
    "    test_df[f'Date_{ticker}'] = pd.to_datetime(test_df[f'Date_{ticker}'])\n",
    "    out_of_sample_df[f'Date_{ticker}'] = pd.to_datetime(out_of_sample_df[f'Date_{ticker}'])\n",
    "\n",
    "    train_df = train_df.dropna()\n",
    "    test_df = test_df.dropna()\n",
    "    out_of_sample_df = out_of_sample_df.dropna()\n",
    "\n",
    "    date_column = f'Date_{ticker}'\n",
    "\n",
    "    train_df = merge_data(train_df, ticker, f'ticker/sentiment_count_{ticker}.csv', date_column)\n",
    "    test_df = merge_data(test_df, ticker, f'ticker/sentiment_count_{ticker}.csv', date_column)\n",
    "    out_of_sample_df = merge_data(out_of_sample_df, ticker, f'ticker/sentiment_count_{ticker}.csv', date_column)\n",
    "\n",
    "    train_df.fillna(0, inplace = True)\n",
    "    test_df.fillna(0, inplace = True)\n",
    "    out_of_sample_df.fillna(0,inplace=True)\n",
    "    \n",
    "    \n",
    "    for col in train_df.columns:\n",
    "        if col != 'positive_return_dummy' and not col.endswith('_L01d'):\n",
    "            new_col_name = col + '_L01d'\n",
    "            train_df.rename(columns={col: new_col_name}, inplace=True)\n",
    "            test_df.rename(columns={col: new_col_name}, inplace=True)\n",
    "            out_of_sample_df.rename(columns={col: new_col_name}, inplace=True)\n",
    "    \n",
    "    included_columns = ['volatility_ratio_L01d',\n",
    "                        'ema_ratio_L01d',\n",
    "                        'sma_ratio_L01d',\n",
    "                        #f'RetMACD_{ticker}_L01d',\n",
    "                        #'negative_L01d','neutral_L01d', 'positive_L01d', 'negative_max_L01d','negative_avg_L01d', 'positive_max_L01d', 'positive_avg_L01d',\n",
    "                        ]\n",
    "    selected_columns_formula = f\"{target_variable} ~ {' + '.join(included_columns)}\"\n",
    "    print(selected_columns_formula)\n",
    "    #best_trend_strategy[ticker].appned(('RetMACD', train_df[f'RetMACD_{ticker}_L01d'].mean()/ train_df[f'RetMACD_{ticker}_L01d'].std()))\n",
    "    #logit_model\n",
    "    mod = smf.logit(formula=selected_columns_formula, data=train_df)\n",
    "    logit_model = mod.fit()\n",
    "    print(logit_model.summary())\n",
    "    \n",
    "    \n",
    "    y_true = test_df['positive_return_dummy']\n",
    "    #print(roc_auc_logit)\n",
    "    \n",
    "    y_train = train_df['positive_return_dummy']\n",
    "    X_train = train_df[included_columns]\n",
    "    tree_model = DecisionTreeClassifier(random_state=42)\n",
    "    tree_model.fit(X_train, y_train)\n",
    "    rf_model = RandomForestClassifier()\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    params = {\n",
    "        'eval_metric': 'logloss',\n",
    "        'learning_rate': 0.01,\n",
    "        'n_estimators': 200,\n",
    "    }\n",
    "    xgb_model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "    dtest = xgb.DMatrix(test_df[included_columns], label = test_df['positive_return_dummy'])\n",
    "    y_pred_logit = logit_model.predict(test_df[included_columns])\n",
    "    y_pred_tree = tree_model.predict(test_df[included_columns])\n",
    "    y_pred_rf = rf_model.predict(test_df[included_columns])\n",
    "    y_pred_xgb = xgb_model.predict(dtest)\n",
    "    \n",
    "    ensemble_predictions = np.maximum.reduce([y_pred_logit,y_pred_tree,y_pred_rf,y_pred_xgb])\n",
    "    \n",
    "    \n",
    "    \n",
    "    roc_auc_logit = roc_auc_score(y_true, y_pred_logit)\n",
    "    roc_auc_tree = roc_auc_score(y_true,y_pred_tree)\n",
    "    roc_auc_rf = roc_auc_score(y_true, y_pred_rf)\n",
    "    roc_auc_xgb = roc_auc_score(y_true, y_pred_xgb)\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    \n",
    "    \n",
    "    threshold = 0.5\n",
    "    signal_logit = (y_pred_logit>threshold).astype(bool)\n",
    "    signal_tree = (y_pred_tree > threshold).astype(bool)\n",
    "    signal_rf = (y_pred_rf > threshold).astype(bool)\n",
    "    signal_model_xgb = (y_pred_xgb > threshold).astype(bool)\n",
    "    signal_ensemble = (ensemble_predictions>threshold).astype(bool)\n",
    "    \n",
    "    pred_logit = pd.DataFrame({'y_pred':signal_logit, 'y_true':test_df['positive_return_dummy']})\n",
    "    pred_tree = pd.DataFrame({'y_pred':signal_tree, 'y_true':test_df['positive_return_dummy']})\n",
    "    pred_rf = pd.DataFrame({'y_pred':signal_rf, 'y_true':test_df['positive_return_dummy']})\n",
    "    pred_xgb = pd.DataFrame({'y_pred':signal_model_xgb, 'y_true':test_df['positive_return_dummy']})\n",
    "    \n",
    "    accuracy_logit = accuracy_score(pred_logit['y_true'], pred_logit['y_pred'])\n",
    "    accuracy_tree = accuracy_score(pred_tree['y_true'], pred_tree['y_pred'])\n",
    "    accuracy_rf = accuracy_score(pred_rf['y_true'], pred_rf['y_pred'])\n",
    "    accuracy_xgb = accuracy_score(pred_xgb['y_true'],pred_xgb['y_pred'])\n",
    "    \n",
    "    signal_logit = pd.DataFrame({'signal_logit': signal_logit,'Date': test_df[f'Date_{ticker}_L01d']})\n",
    "    signal_logit.set_index('Date', inplace=True)\n",
    "    signal_tree = pd.DataFrame({'signal_tree': signal_tree,'Date': test_df[f'Date_{ticker}_L01d']})\n",
    "    signal_tree.set_index('Date', inplace=True)\n",
    "    signal_rf = pd.DataFrame({'signal_rf': signal_rf, 'Date': test_df[f'Date_{ticker}_L01d']})\n",
    "    signal_rf.set_index('Date', inplace=True)\n",
    "    signals_df_xgb = pd.DataFrame({'signal_xgb': signal_model_xgb, 'Date': test_df[f'Date_{ticker}_L01d']})\n",
    "    signals_df_xgb.set_index('Date', inplace=True)\n",
    "    signals_df_ensemble = pd.DataFrame({'signal_ensemble': signal_ensemble, 'Date': test_df[f'Date_{ticker}_L01d']})\n",
    "    signals_df_ensemble.set_index('Date', inplace=True)\n",
    "    \n",
    "    #print(signal_tree.head())\n",
    "    #print(signal_rf.head())\n",
    "    #print(signal_model_xgb.head())\n",
    "    \n",
    "    price_logit = pd.DataFrame({'Date': test_df[f'Date_{ticker}_L01d'],'signal_logit': test_df[f'Close_{ticker}_L01d']})\n",
    "    price_logit.set_index('Date', inplace=True)\n",
    "    price_tree = pd.DataFrame({'Date': test_df[f'Date_{ticker}_L01d'],'signal_tree': test_df[f'Close_{ticker}_L01d']})\n",
    "    price_tree.set_index('Date', inplace=True)\n",
    "    price_rf = pd.DataFrame({'Date': test_df[f'Date_{ticker}_L01d'],'signal_rf': test_df[f'Close_{ticker}_L01d']})\n",
    "    price_rf.set_index('Date', inplace=True)\n",
    "    price_df_xgb = pd.DataFrame({'signal_xgb': test_df[f'Close_{ticker}_L01d'], 'Date': test_df[f'Date_{ticker}_L01d']})\n",
    "    price_df_xgb.set_index('Date', inplace=True)\n",
    "    price_df_ensemble = pd.DataFrame({'signal_ensemble': test_df[f'Close_{ticker}_L01d'], 'Date': test_df[f'Date_{ticker}_L01d']})\n",
    "    price_df_ensemble.set_index('Date', inplace=True)\n",
    "    \n",
    "    \n",
    "    stratergy_logit = bt.Strategy(\n",
    "        'Strategy_logit',\n",
    "        [bt.algos.SelectWhere(signal=signal_logit), bt.algos.WeighEqually(), bt.algos.Rebalance()]\n",
    "    )\n",
    "    bt_result_logit = bt.Backtest(stratergy_logit, price_logit)\n",
    "    res_logit = bt.run(bt_result_logit)\n",
    "    \n",
    "    stratergy_tree = bt.Strategy(\n",
    "        'Strategy_tree',\n",
    "        [bt.algos.SelectWhere(signal=signal_tree), bt.algos.WeighEqually(), bt.algos.Rebalance()]\n",
    "    )\n",
    "    bt_result_tree = bt.Backtest(stratergy_tree, price_tree)\n",
    "    res_tree = bt.run(bt_result_tree)\n",
    "    \n",
    "    stratergy_rf = bt.Strategy(\n",
    "        'Strategy_rf',\n",
    "        [bt.algos.SelectWhere(signal=signal_rf), bt.algos.WeighEqually(), bt.algos.Rebalance()]\n",
    "    )\n",
    "    bt_result_rf = bt.Backtest(stratergy_rf, price_rf)\n",
    "    res_rf = bt.run(bt_result_rf)\n",
    "\n",
    "    stratergy_xgb = bt.Strategy(\n",
    "        'Strategy_xgb',\n",
    "        [bt.algos.SelectWhere(signal=signals_df_xgb), bt.algos.WeighEqually(), bt.algos.Rebalance()]\n",
    "    )\n",
    "    bt_result_xgb = bt.Backtest(stratergy_xgb, price_df_xgb)\n",
    "    res_xgb = bt.run(bt_result_xgb)\n",
    "    \n",
    "    stratergy_ensemble = bt.Strategy(\n",
    "        'Strategy_ensemble',\n",
    "        [bt.algos.SelectWhere(signal=signals_df_ensemble), bt.algos.WeighEqually(), bt.algos.Rebalance()]\n",
    "    )\n",
    "    bt_result_ensemble = bt.Backtest(stratergy_ensemble, price_df_ensemble)\n",
    "    res_ensemble = bt.run(bt_result_ensemble)\n",
    "    \n",
    "    \n",
    "    from tabulate import tabulate\n",
    "    table_data = [\n",
    "        ['LOGIT', res_logit.stats['Strategy_logit']['total_return'], res_logit.stats['Strategy_logit']['calmar'], res_logit.stats['Strategy_logit']['daily_sharpe'], res_logit.stats['Strategy_logit']['daily_sortino'],res_logit.stats['Strategy_logit']['max_drawdown'], res_logit.stats['Strategy_logit']['daily_vol']],\n",
    "        ['DT', res_tree.stats['Strategy_tree']['total_return'], res_tree.stats['Strategy_tree']['calmar'], res_tree.stats['Strategy_tree']['daily_sharpe'], res_tree.stats['Strategy_tree']['daily_sortino'],res_tree.stats['Strategy_tree']['max_drawdown'], res_tree.stats['Strategy_tree']['daily_vol']],\n",
    "        ['RF', res_rf.stats['Strategy_rf']['total_return'], res_rf.stats['Strategy_rf']['calmar'], res_rf.stats['Strategy_rf']['daily_sharpe'], res_rf.stats['Strategy_rf']['daily_sortino'], res_rf.stats['Strategy_rf']['max_drawdown'],res_rf.stats['Strategy_rf']['daily_vol']],\n",
    "        ['XGB', res_xgb.stats['Strategy_xgb']['total_return'], res_xgb.stats['Strategy_xgb']['calmar'], res_xgb.stats['Strategy_xgb']['daily_sharpe'], res_xgb.stats['Strategy_xgb']['daily_sortino'], res_xgb.stats['Strategy_xgb']['max_drawdown'],res_xgb.stats['Strategy_xgb']['daily_vol']],\n",
    "        ['ENSEMBLE', res_ensemble.stats['Strategy_ensemble']['total_return'], res_ensemble.stats['Strategy_ensemble']['calmar'], res_ensemble.stats['Strategy_ensemble']['daily_sharpe'], res_ensemble.stats['Strategy_ensemble']['daily_sortino'], res_ensemble.stats['Strategy_ensemble']['max_drawdown'],res_ensemble.stats['Strategy_ensemble']['daily_vol']],\n",
    "\n",
    "    ]\n",
    "    \n",
    "    headers = ['Model', 'Total Return', 'Calmar', 'Daily Sharpe', 'Sortino','Drawdown', 'Daily Volatility']\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "    #logit_signal = (y_pred_logit > threshold).astype(int)\n",
    "    #tree_signal = (y_pred_tree > threshold).astype(int)\n",
    "    #rf_signal = (y_pred_rf>threshold).astype(int)\n",
    "    #xgb_signal = (y_pred_xgb>threshold).astype(int)\n",
    "    \n",
    "    signals_df = pd.DataFrame({\n",
    "        'signal_logit': (y_pred_logit > threshold).astype(int)* 2 - 1,\n",
    "        'signal_tree': (y_pred_tree > threshold).astype(int)* 2 - 1,\n",
    "        'signal_rf': (y_pred_rf > threshold).astype(int)* 2 - 1,\n",
    "        'signal_xgb': (y_pred_xgb > threshold).astype(int)* 2 - 1,\n",
    "        'signal_ensemble':(ensemble_predictions>threshold).astype(int)*2-1\n",
    "    })\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(res_logit.prices, label = 'logit')\n",
    "    plt.plot(res_tree.prices, label='Decision Tree')\n",
    "    plt.plot(res_rf.prices, label='Random Forest')\n",
    "    plt.plot(res_xgb.prices, label = 'XGB')\n",
    "    plt.plot(res_ensemble.prices, label = 'ENSEMBLE')\n",
    "    plt.title(f'{ticker}: logit vs Decision_tree vs Random forest vs XGB vs ensemble')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'backtest/{ticker}_with_news_w_ensemble.png',format='png')\n",
    "    plt.show()\n",
    "    signals = ['logit', 'tree', 'xgb', 'rf','ensemble']\n",
    "    #ticker = 'NVDA'\n",
    "    best_strategy, sharpe_ratios = calculate_best_strategy(test_df, signals, ticker)\n",
    "    print(f\"Best strategy for {ticker}: {best_strategy}, Sharpe ratio: {sharpe_ratios[best_strategy]}\")\n",
    "    test_df.to_csv(f'ticker/backtest-test/{ticker}_with_news_w_ensemble.csv', index = False)\n",
    "    ticker_strategies[ticker] = {'Best Strategy': best_strategy, 'Sharpe Ratio': sharpe_ratios[best_strategy]}\n",
    "    \n",
    "    best_strategy_test = ticker_strategies[ticker]['Best Strategy']\n",
    "    #print(best_strategy_test)\n",
    "    \n",
    "    model_name =  f'{best_strategy_test}_model'\n",
    "    if best_strategy_test == 'ensemble':\n",
    "        dtest = xgb.DMatrix(out_of_sample_df[included_columns], label = out_of_sample_df['positive_return_dummy'])\n",
    "        y_pred_logit = logit_model.predict(out_of_sample_df[included_columns])\n",
    "        y_pred_tree = tree_model.predict(out_of_sample_df[included_columns])\n",
    "        y_pred_rf = rf_model.predict(out_of_sample_df[included_columns])\n",
    "        y_pred_xgb = xgb_model.predict(dtest)\n",
    "        y_pred_best = np.maximum.reduce([y_pred_logit,y_pred_tree,y_pred_rf,y_pred_xgb])\n",
    "    elif best_strategy_test == 'xgb':\n",
    "        best_model = eval(model_name)\n",
    "        dtest = xgb.DMatrix(out_of_sample_df[included_columns], label = out_of_sample_df['positive_return_dummy'])\n",
    "        y_pred_best = best_model.predict(dtest)\n",
    "    else:\n",
    "        best_model = eval(model_name)\n",
    "        y_pred_best = best_model.predict(out_of_sample_df[included_columns])\n",
    "    signals_df = pd.DataFrame({\n",
    "        'signal_best': (y_pred_best > threshold).astype(int)* 2 - 1,\n",
    "    })\n",
    "    sharpe_ratio=calculate_sharpe_ratio(out_of_sample_df, signals_df,'best', ticker)\n",
    "    print(sharpe_ratio)\n",
    "    #print(out_of_sample_df)\n",
    "    out_of_sample_df.to_csv(f'ticker/backtest-oos/{ticker}_with_news_w_ensemble.csv', index = False)\n",
    "    best_tuple = max(best_trend_strategy[ticker], key=lambda x: x[1])\n",
    "\n",
    "    trend_strategy[ticker]={'strategy':best_tuple[0],'sharpe':best_tuple[1],'logit':accuracy_logit,'tree':accuracy_tree,\n",
    "                           'rf':accuracy_rf,'xgb':accuracy_xgb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15aad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ee0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b0e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize the concatenated DataFrame and other variables\n",
    "concatenated_df = pd.DataFrame()\n",
    "ticker_final = None\n",
    "\n",
    "# Assuming ticker_strategies is a dictionary that contains ticker information and best strategy\n",
    "for ticker, strategy_info in ticker_strategies.items():\n",
    "    # Get the best strategy for the current ticker\n",
    "    ticker_final = ticker\n",
    "    best_strategy = strategy_info['Best Strategy']\n",
    "    \n",
    "    # Open the file for the current ticker\n",
    "    file_name = f'backtest/{ticker}_with_news_w_ensemble.csv'\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    # Extract the column named f'ret_{Best_Strategy}' and rename it\n",
    "    column_name = f'ret_{best_strategy}'\n",
    "    df[f'ret_{ticker}'] = df.get(column_name, pd.NA)  # Uses `pd.NA` if the column is missing\n",
    "\n",
    "    # Concatenate the extracted column to the DataFrame\n",
    "    concatenated_df = pd.concat([concatenated_df, df[f'ret_{ticker}']], axis=1)\n",
    "\n",
    "# Check the shapes of the DataFrames before merging\n",
    "print(f\"Shape of concatenated_df: {concatenated_df.shape}\")\n",
    "print(f\"Shape of test_df: {test_df.shape}\")\n",
    "\n",
    "# Check the column names in concatenated_df and test_df\n",
    "print(f\"concatenated_df columns: {concatenated_df.columns}\")\n",
    "print(f\"test_df columns: {test_df.columns}\")\n",
    "\n",
    "# Ensure 'Date' column exists in concatenated_df\n",
    "if 'Date' not in concatenated_df.columns:\n",
    "    # Check if any column might be a date column by inspecting the columns\n",
    "    date_columns = [col for col in concatenated_df.columns if 'Date' in col]\n",
    "    if date_columns:\n",
    "        # Renaming the first date-like column found to 'Date'\n",
    "        concatenated_df.rename(columns={date_columns[0]: 'Date'}, inplace=True)\n",
    "    else:\n",
    "        print(\"Error: No date column found in concatenated_df.\")\n",
    "        # Further handling, such as exiting or additional logic, can be added here\n",
    "\n",
    "# Check if 'Date' exists in test_df and if the other necessary column is there\n",
    "if 'Date' not in test_df.columns or f'Date_{ticker_final}_L01d' not in test_df.columns:\n",
    "    print(f\"Error: One or more required date columns are missing in test_df.\")\n",
    "    # Examine test_df to handle missing columns accordingly\n",
    "\n",
    "# After ensuring both DataFrames have the 'Date' column, check if the rows align\n",
    "if len(concatenated_df) == len(test_df):\n",
    "    concatenated_df.set_index(test_df[f'Date_{ticker_final}_L01d'], inplace=True)\n",
    "else:\n",
    "    print(f\"Row length mismatch: {len(concatenated_df)} vs {len(test_df)}. Aligning the DataFrames.\")\n",
    "    \n",
    "    # Merge DataFrames on the 'Date' column from both DataFrames\n",
    "    # Make sure both DataFrames have the 'Date' column for merging\n",
    "    if 'Date' in concatenated_df.columns:\n",
    "        concatenated_df = pd.merge(concatenated_df, test_df[['Date', f'Date_{ticker_final}_L01d']], on='Date', how='inner')\n",
    "        # After merging, set the index to the new Date column from test_df\n",
    "        concatenated_df.set_index(f'Date_{ticker_final}_L01d', inplace=True)\n",
    "    else:\n",
    "        print(\"Error: Unable to find 'Date' column for merging.\")\n",
    "\n",
    "# Display the resulting concatenated DataFrame\n",
    "print(concatenated_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2477851",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df.to_csv('test_portfolio_final_with_news_w_ensemble.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f272a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.DataFrame()\n",
    "ticker_final = None\n",
    "# Iterate through each ticker and its corresponding best strategy\n",
    "for ticker, strategy_info in trend_strategy.items():\n",
    "    # Get the best strategy for the current ticker\n",
    "    ticker_final = ticker\n",
    "    best_strategy = strategy_info['strategy']\n",
    "    strategy = best_strategy[:3].lower()\n",
    "    # Open the file for the current ticker\n",
    "    file_name = f'ticker/backtest-test/{ticker}_with_news_w_ensemble.csv'\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    # Extract the column named f'ret_{Best_Strategy}' and rename it\n",
    "    if strategy == 'ret':\n",
    "        column_name = 'RetMACD_L01d'\n",
    "    else:\n",
    "        column_name = f'ret_{strategy}_ratio_L01d'\n",
    "    df[f'ret_{ticker}'] = df[column_name]\n",
    "    \n",
    "    # Concatenate the extracted column to the DataFrame\n",
    "    concatenated_df = pd.concat([concatenated_df, df[f'ret_{ticker}']], axis=1)\n",
    "concatenated_df.set_index(test_df[f'Date_{ticker_final}_L01d'], inplace=True)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "print(concatenated_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb58e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df.to_csv('trend_portfolio_final_with_news_w_ensemble.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987af107",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.DataFrame()\n",
    "ticker_final = None\n",
    "# Iterate through each ticker and its corresponding best strategy\n",
    "for ticker, _ in ticker_strategies.items():\n",
    "    # Get the best strategy for the current ticker\n",
    "    ticker_final = ticker\n",
    "    #best_strategy = strategy_info['Best Strategy']\n",
    "    \n",
    "    # Open the file for the current ticker\n",
    "    file_name = f'ticker/backtest-oos/{ticker}_with_news_w_ensemble.csv'\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    # Extract the column named f'ret_{Best_Strategy}' and rename it\n",
    "    column_name = f'ret_best'\n",
    "    df[f'ret_{ticker}'] = df[column_name]\n",
    "    \n",
    "    # Concatenate the extracted column to the DataFrame\n",
    "    concatenated_df = pd.concat([concatenated_df, df[f'ret_{ticker}']], axis=1)\n",
    "concatenated_df.set_index(out_of_sample_df[f'Date_{ticker_final}_L01d'], inplace=True)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "print(concatenated_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4aa68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df.to_csv('oos_portfolio_final_with_news_w_ensemble.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b798ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.DataFrame()\n",
    "ticker_final = None\n",
    "# Iterate through each ticker and its corresponding best strategy\n",
    "for ticker, strategy_info in trend_strategy.items():\n",
    "    # Get the best strategy for the current ticker\n",
    "    ticker_final = ticker\n",
    "    #best_strategy = strategy_info['Best Strategy']\n",
    "    best_strategy = strategy_info['strategy']\n",
    "    # Open the file for the current ticker\n",
    "    strategy = best_strategy[:3].lower()\n",
    "    \n",
    "    file_name = f'ticker/backtest-oos/{ticker}_with_news_w_ensemble.csv'\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    \n",
    "    if strategy == 'ret':\n",
    "        column_name = 'RetMACD_L01d'\n",
    "    else:\n",
    "        column_name = f'ret_{strategy}_ratio_L01d'\n",
    "    df[f'ret_{ticker}'] = df[column_name]\n",
    "    \n",
    "    # Concatenate the extracted column to the DataFrame\n",
    "    concatenated_df = pd.concat([concatenated_df, df[f'ret_{ticker}']], axis=1)\n",
    "concatenated_df.set_index(out_of_sample_df[f'Date_{ticker_final}_L01d'], inplace=True)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "print(concatenated_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f68b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df.to_csv('oos_trend_portfolio_final_with_news_w_ensemble.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b147b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
